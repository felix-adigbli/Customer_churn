{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import  LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding and Definition of the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer churn is the rate at which customers stop doing business with a company. Customers may decide to cease using a company's product or service for several reasons, including cost, unhappiness with the service and product selection, or poor customer service. For telco businesses, it is essential to both draw in new clients and curb consumer churn. When consumers leave, it is quite expensive for the business. A high churn rate adversely affects profits, impede growth and considerable impact on the market share. Predicting whether a particular consumer will go, or stay is the main challenge. Finding the crucial elements of churning presents a unique problem.\n",
    "\n",
    "The key challenge is to predict if an individual customer will churn or not. In this project I will use supervised machine leaning to predict if a telco customer will churn or not. I will also do parameter tuning to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABOUT THE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In IBM Cognos Analytics 11.1.3, the data module that is named Telco Customer Churn in the Base Samples was enhanced to provide a wider narrative.The Telco customer churn data contains information about a fictional telco company that provided home phone and Internet services to 7043 customers in California in Q3. It indicates which customers have left, stayed, or signed up for their service. Multiple important demographics are included for each customer, as well as a Satisfaction Score, Churn Score, and Customer Lifetime Value (CLTV) index.\n",
    "The Telco customer churn data module is composed of 5 uploaded files:\n",
    "\n",
    "    Telco_customer_churn_demographics.xlsx\n",
    "    Telco_customer_churn_location.xlsx\n",
    "    Telco_customer_churn_population.xlsx\n",
    "    Telco_customer_churn_services.xlsx\n",
    "    Telco_customer_churn_status.xlsx\n",
    "\n",
    "The variables in each data set are described below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographics\n",
    "\n",
    "CustomerID: A unique ID that identifies each customer.\n",
    "\n",
    "Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.\n",
    "\n",
    "Gender: The customer’s gender: Male, Female\n",
    "\n",
    "Age: The customer’s current age, in years, at the time the fiscal quarter ended.\n",
    "\n",
    "Senior Citizen: Indicates if the customer is 65 or older: Yes, No\n",
    "\n",
    "Married: Indicates if the customer is married: Yes, No\n",
    "\n",
    "Dependents: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.\n",
    "\n",
    "Number of Dependents: Indicates the number of dependents that live with the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_excel(\"dataset/Telco_customer_churn_demographics.xlsx\")\n",
    "demographics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location\n",
    "\n",
    "CustomerID: A unique ID that identifies each customer.\n",
    "\n",
    "Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.\n",
    "\n",
    "Country: The country of the customer’s primary residence.\n",
    "\n",
    "State: The state of the customer’s primary residence.\n",
    "\n",
    "City: The city of the customer’s primary residence.\n",
    "\n",
    "Zip Code: The zip code of the customer’s primary residence.\n",
    "\n",
    "Lat Long: The combined latitude and longitude of the customer’s primary residence.\n",
    "\n",
    "Latitude: The latitude of the customer’s primary residence.\n",
    "\n",
    "Longitude: The longitude of the customer’s primary residence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pd.read_excel(\"dataset/Telco_customer_churn_location.xlsx\")\n",
    "location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population\n",
    "\n",
    "ID: A unique ID that identifies each row.\n",
    "\n",
    "Zip Code: The zip code of the customer’s primary residence.\n",
    "\n",
    "Population: A current population estimate for the entire Zip Code area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_excel(\"dataset/Telco_customer_churn_population.xlsx\")\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Services\n",
    "\n",
    "CustomerID: A unique ID that identifies each customer.\n",
    "\n",
    "Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.\n",
    "\n",
    "Quarter: The fiscal quarter that the data has been derived from (e.g. Q3).\n",
    "\n",
    "Referred a Friend: Indicates if the customer has ever referred a friend or family member to this company: Yes, No\n",
    "\n",
    "Number of Referrals: Indicates the number of referrals to date that the customer has made.\n",
    "\n",
    "Tenure in Months: Indicates the total amount of months that the customer has been with the company by the end of the quarter specified above.\n",
    "\n",
    "Offer: Identifies the last marketing offer that the customer accepted, if applicable. Values include None, Offer A, Offer B, Offer C, Offer D, and Offer E.\n",
    "\n",
    "Phone Service: Indicates if the customer subscribes to home phone service with the company: Yes, No\n",
    "\n",
    "Avg Monthly Long Distance Charges: Indicates the customer’s average long distance charges, calculated to the end of the quarter specified above.\n",
    "\n",
    "Multiple Lines: Indicates if the customer subscribes to multiple telephone lines with the company: Yes, No\n",
    "\n",
    "Internet Service: Indicates if the customer subscribes to Internet service with the company: No, DSL, Fiber Optic, Cable.\n",
    "\n",
    "Avg Monthly GB Download: Indicates the customer’s average download volume in gigabytes, calculated to the end of the quarter specified above.\n",
    "\n",
    "Online Security: Indicates if the customer subscribes to an additional online security service provided by the company: Yes, No\n",
    "\n",
    "Online Backup: Indicates if the customer subscribes to an additional online backup service provided by the company: Yes, No\n",
    "\n",
    "Device Protection Plan: Indicates if the customer subscribes to an additional device protection plan for their Internet equipment provided by the company: Yes, No\n",
    "\n",
    "Premium Tech Support: Indicates if the customer subscribes to an additional technical support plan from the company with reduced wait times: Yes, No\n",
    "\n",
    "Streaming TV: Indicates if the customer uses their Internet service to stream television programing from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n",
    "\n",
    "Streaming Movies: Indicates if the customer uses their Internet service to stream movies from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n",
    "\n",
    "Streaming Music: Indicates if the customer uses their Internet service to stream music from a third party provider: Yes, No. The company does not charge an additional fee for this service.\n",
    "\n",
    "Unlimited Data: Indicates if the customer has paid an additional monthly fee to have unlimited data downloads/uploads: Yes, No\n",
    "\n",
    "Contract: Indicates the customer’s current contract type: Month-to-Month, One Year, Two Year.\n",
    "\n",
    "Paperless Billing: Indicates if the customer has chosen paperless billing: Yes, No\n",
    "\n",
    "Payment Method: Indicates how the customer pays their bill: Bank Withdrawal, Credit Card, Mailed Check\n",
    "\n",
    "Monthly Charge: Indicates the customer’s current total monthly charge for all their services from the company.\n",
    "\n",
    "Total Charges: Indicates the customer’s total charges, calculated to the end of the quarter specified above.\n",
    "\n",
    "Total Refunds: Indicates the customer’s total refunds, calculated to the end of the quarter specified above.\n",
    "\n",
    "Total Extra Data Charges: Indicates the customer’s total charges for extra data downloads above those specified in their plan, by the end of the quarter specified above.\n",
    "\n",
    "Total Long Distance Charges: Indicates the customer’s total charges for long distance above those specified in their plan, by the end of the quarter specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = pd.read_excel(\"dataset/Telco_customer_churn_services.xlsx\")\n",
    "services.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status\n",
    "\n",
    "CustomerID: A unique ID that identifies each customer.\n",
    "\n",
    "Count: A value used in reporting/dashboarding to sum up the number of customers in a filtered set.\n",
    "\n",
    "Quarter: The fiscal quarter that the data has been derived from (e.g. Q3).\n",
    "\n",
    "Satisfaction Score: A customer’s overall satisfaction rating of the company from 1 (Very Unsatisfied) to 5 (Very Satisfied).\n",
    "\n",
    "Satisfaction Score Label: Indicates the text version of the score (1-5) as a text string.\n",
    "\n",
    "Customer Status: Indicates the status of the customer at the end of the quarter: Churned, Stayed, or Joined\n",
    "\n",
    "Churn Label: Yes = the customer left the company this quarter. No = the customer remained with the company. Directly related to Churn Value.\n",
    "\n",
    "Churn Value: 1 = the customer left the company this quarter. 0 = the customer remained with the company. Directly related to Churn Label.\n",
    "\n",
    "Churn Score: A value from 0-100 that is calculated using the predictive tool IBM SPSS Modeler. The model incorporates multiple factors known to cause churn. The higher the score, the more likely the customer will churn.\n",
    "\n",
    "Churn Score Category: A calculation that assigns a Churn Score to one of the following categories: 0-10, 11-20, 21-30, 31-40, 41-50, 51-60, 61-70, 71-80, 81-90, and 91-100\n",
    "\n",
    "CLTV: Customer Lifetime Value. A predicted CLTV is calculated using corporate formulas and existing data. The higher the value, the more valuable the customer. High value customers should be monitored for churn.\n",
    "\n",
    "CLTV Category: A calculation that assigns a CLTV value to one of the following categories: 2000-2500, 2501-3000, 3001-3500, 3501-4000, 4001-4500, 4501-5000, 5001-5500, 5501-6000, 6001-6500, and 6501-7000.\n",
    "\n",
    "Churn Category: A high-level category for the customer’s reason for churning: Attitude, Competitor, Dissatisfaction, Other, Price. When they leave the company, all customers are asked about their reasons for leaving. Directly related to Churn Reason.\n",
    "\n",
    "Churn Reason: A customer’s specific reason for leaving the company. Directly related to Churn Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_excel(\"dataset/Telco_customer_churn_status.xlsx\")\n",
    "status.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Demographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of Demographic Data and Insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a figure to hold the visualizations for the \"Age\" variable\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram for \"Age\"\n",
    "sns.histplot(demographics['Age'], kde=False, ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Histogram of Age')\n",
    "\n",
    "# Kernel Density Estimate for \"Age\"\n",
    "sns.kdeplot(demographics['Age'], ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Kernel Density Estimate of Age')\n",
    "\n",
    "# Cumulative Distribution Function for \"Age\"\n",
    "sns.kdeplot(demographics['Age'], cumulative=True, ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Cumulative Distribution Function of Age')\n",
    "\n",
    "# Box-and-Whisker Plot for \"Age\"\n",
    "sns.boxplot(y=demographics['Age'], ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Box-and-Whisker Plot of Age')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The histogram and kernel density estimate (KDE) for age show a broad distribution, suggesting a diverse customer base in terms of age. There's no single dominant age group, indicating that the services offered by Telco appeal to a wide age range of customers.\n",
    "The cumulative distribution function (CDF) further confirms this diversity, with a steady increase across the age spectrum, showing that the customer base is not skewed towards any specific age group.\n",
    "The box-and-whisker plot reveals the median age lies in the middle age range, with some outliers indicating that there are customers who are significantly older than the median, which supports the diversity in customer age.\n",
    "Number of Dependents\n",
    "The histogram and KDE for the number of dependents suggest that a significant portion of the customer base has few to no dependents. This could indicate that the services are popular among individuals and small families.\n",
    "The CDF shows that a large proportion of customers have less than two dependents, reinforcing the idea that the majority of customers are either single individuals or small families.\n",
    "The box-and-whisker plot for the number of dependents indicates that the median number of dependents is low, with a few outliers having a higher number of dependents. This suggests that while the service appeals to customers with various family sizes, those with larger families are less common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure to hold the visualizations for the categorical variables\n",
    "fig, axs = plt.subplots(3, 2, figsize=(14, 15))\n",
    "categorical_variables = ['Gender', 'Under 30',\n",
    "                         'Senior Citizen', 'Married', 'Dependents']\n",
    "\n",
    "for ax, variable in zip(axs.flatten(), categorical_variables):\n",
    "    sns.countplot(x=variable, data=demographics, ax=ax)\n",
    "    ax.set_title(f'Distribution of {variable}')\n",
    "\n",
    "# Adjust layout and remove the empty subplot\n",
    "plt.tight_layout()\n",
    "fig.delaxes(axs.flatten()[5])  # Remove the last subplot which is empty\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender\n",
    "The count plot for gender shows a relatively balanced distribution between male and female customers, indicating that the service offerings cater equally well to both genders.\n",
    "Under 30 and Senior Citizen\n",
    "The distribution of customers under 30 and those classified as senior citizens provides insights into the age-related demographics of the customer base. The service appeals to a broad age range, including both younger individuals and senior citizens, suggesting diverse usage and needs across different age groups.\n",
    "Married\n",
    "The count plot for marital status reveals a mix of married and unmarried customers, indicating variability in the customer base's social and family structures. This diversity could influence the types of services and plans that are popular among different segments of customers.\n",
    "Dependents\n",
    "Similar to the numeric analysis of dependents, the categorical count plot shows that a sizable portion of the customer base does not have dependents, which could correlate with the number of single individuals or couples without children using Telco services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# understanding Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 cities by Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "city_counts = location['City'].value_counts()\n",
    "# Show top 10 cities for brevity\n",
    "sns.barplot(y=city_counts.index[:10], x=city_counts.values[:10])\n",
    "plt.title('Top 10 Cities by Customer Count')\n",
    "plt.xlabel('Number of Customers')\n",
    "plt.ylabel('City')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customer distibution by zipcode (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "zip_code_counts = location['Zip Code'].value_counts()\n",
    "sns.barplot(y=zip_code_counts.index[:10].astype(\n",
    "    str), x=zip_code_counts.values[:10])\n",
    "plt.title('Top 10 Zip Codes by Customer Count')\n",
    "plt.xlabel('Number of Customers')\n",
    "plt.ylabel('Zip Code')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanfing Service\n",
    "Selecting some important variables for anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenure in Months and  Monthly Charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables_selected = ['Tenure in Months', 'Monthly Charge']\n",
    "\n",
    "# Create figure for Box-and-Whisker Plot, Histogram, KDE, and CDF\n",
    "fig, axs = plt.subplots(len(numerical_variables_selected), 4, figsize=(20, 10))\n",
    "\n",
    "for i, variable in enumerate(numerical_variables_selected):\n",
    "    # Box-and-Whisker Plot\n",
    "    sns.boxplot(x=services[variable], ax=axs[i, 0])\n",
    "    axs[i, 0].set_title(f'Box-and-Whisker Plot of {variable}')\n",
    "\n",
    "    # Histogram\n",
    "    sns.histplot(services[variable], kde=False, ax=axs[i, 1])\n",
    "    axs[i, 1].set_title(f'Histogram of {variable}')\n",
    "\n",
    "    # Kernel Density Estimate\n",
    "    sns.kdeplot(services[variable], ax=axs[i, 2])\n",
    "    axs[i, 2].set_title(f'Kernel Density Estimate of {variable}')\n",
    "\n",
    "    # Cumulative Distribution Function\n",
    "    sns.kdeplot(services[variable], cumulative=True, ax=axs[i, 3])\n",
    "    axs[i, 3].set_title(f'Cumulative Distribution Function of {variable}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms and kernel density estimates (KDE) for \"Tenure in Months\" and \"Monthly Charge\" provide insights into two key aspects of customer service engagement and billing:\n",
    "\n",
    "Tenure in Months: The distribution of tenure among customers indicates the spread of customer loyalty and how long customers have been with the service. The histogram and KDE suggest a mix of newly acquired customers and those with longer tenure, indicating a diverse customer base in terms of service duration.\n",
    "\n",
    "Monthly Charge: These visualizations show the distribution of monthly charges that customers incur. The spread of monthly charges highlights the variety of service plans customers are subscribed to, with some variability in how much customers are paying per month\n",
    "\n",
    "The Cumulative Distribution Function (CDF) and Box-and-Whisker Plots for \"Tenure in Months\" and \"Monthly Charge\" reveal additional insights into the dataset:\n",
    "\n",
    "Tenure in Months:\n",
    "\n",
    "The CDF shows a gradual increase, indicating a steady accumulation of customers over time. The curve suggests a significant proportion of customers have relatively short tenure, with a steady increase in tenure length across the customer base.\n",
    "The Box-and-Whisker Plot highlights the median tenure, along with the interquartile range, showing a wide spread in customer tenure. The presence of outliers suggests some customers have been with the service for a very long time compared to the majority.\n",
    "Monthly Charge:\n",
    "\n",
    "The CDF for monthly charges demonstrates that a large portion of customers pay lower monthly fees, with a gradual increase towards higher charges. This indicates a variety of service plans and options that cater to different customer needs and budgets.\n",
    "The Box-and-Whisker Plot reveals the median monthly charge and the range of charges customers incur. The spread and outliers indicate variability in how much customers are willing to pay for services, reflecting the diverse offering of service plans.\n",
    "These analyses provide a comprehensive view of customer tenure and billing, reflecting the diversity in customer engagement and service preferences within the Telco customer base. Understanding these patterns is crucial for tailoring customer service, retention strategies, and pricing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables\n",
    "Selecting key categorical variables for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Offer', 'Contract', 'Payment Method']\n",
    "\n",
    "# Create figure for count plots\n",
    "fig, axs = plt.subplots(len(categorical_variables), 1, figsize=(8, 12))\n",
    "\n",
    "for i, variable in enumerate(categorical_variables):\n",
    "    sns.countplot(y=services[variable], ax=axs[i])\n",
    "    axs[i].set_title(f'Count Plot of {variable}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count plots for \"Offer\", \"Contract\", and \"Payment Method\" reveal significant insights into the preferences and behaviors of Telco's customer base regarding service offers, contract types, and payment methods:\n",
    "\n",
    "Offer: The distribution shows which promotional offers are more popular among customers. This insight can help Telco understand which offers are most attractive and potentially why certain offers may be leading to higher customer acquisition or retention.\n",
    "\n",
    "Contract: This plot illustrates the variety of contract lengths customers are enrolled in, from month-to-month to longer-term contracts. The distribution across different contract types can inform strategies around customer loyalty and retention, highlighting the balance between flexibility and commitment in customer preferences.\n",
    "\n",
    "Payment Method: The distribution of payment methods used by customers indicates preferences for transaction methods, whether through bank withdrawals, credit cards, or other means. Understanding payment method preferences can help in tailoring billing processes and improving customer satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understing the Status of the customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualizations for \"Satisfaction Score\" and \"CLTV\" (Customer Lifetime Value) provide valuable insights into these numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
    "\n",
    "variables_to_plot = ['Satisfaction Score', 'CLTV']\n",
    "\n",
    "for i, variable in enumerate(variables_to_plot):\n",
    "    # Box-and-Whisker Plot\n",
    "    sns.boxplot(x=status[variable], ax=axs[i, 0])\n",
    "    axs[i, 0].set_title(f'Box-and-Whisker Plot of {variable}')\n",
    "\n",
    "    # Histogram\n",
    "    sns.histplot(status[variable], kde=False, ax=axs[i, 1])\n",
    "    axs[i, 1].set_title(f'Histogram of {variable}')\n",
    "\n",
    "    # Kernel Density Estimate\n",
    "    sns.kdeplot(status[variable], ax=axs[i, 2])\n",
    "    axs[i, 2].set_title(f'Kernel Density Estimate of {variable}')\n",
    "\n",
    "    # Cumulative Distribution Function\n",
    "    sns.kdeplot(status[variable], cumulative=True, ax=axs[i, 3])\n",
    "    axs[i, 3].set_title(f'Cumulative Distribution Function of {variable}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box-and-Whisker Plot: Shows the distribution, median, quartiles, and any potential outliers for both variables. For \"Satisfaction Score\", this plot can highlight the range of satisfaction among customers, while for \"CLTV\", it indicates the spread of customer lifetime values, identifying high-value customers.\n",
    "\n",
    "Histogram: Reveals the frequency distribution of values. The histogram for \"Satisfaction Score\" might show common satisfaction levels among customers, while the \"CLTV\" histogram indicates the distribution of customer lifetime values, helping identify common value ranges.\n",
    "\n",
    "Kernel Density Estimate (KDE): Provides a smooth, continuous curve representing the distribution of each variable. The KDE helps visualize the density of satisfaction scores and customer lifetime values, identifying peaks where values are more concentrated.\n",
    "\n",
    "Cumulative Distribution Function (CDF): Shows the cumulative probability for each variable, offering insight into the proportion of customers below certain satisfaction scores or CLTV thresholds. This is particularly useful for understanding how satisfaction or value accumulates across the customer base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Customer Status', 'Churn Reason', 'Churn Category']\n",
    "for variable in categorical_variables:\n",
    "    plt.figure(figsize=(10, len(status[variable].unique()) * 0.5))\n",
    "    order = status[variable].value_counts().index\n",
    "    sns.countplot(y=status[variable], order=order)\n",
    "    plt.title(f'Count Plot of {variable}')\n",
    "    plt.xlabel('Number of Customers')\n",
    "    plt.ylabel(variable)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count plots for \"Customer Status\" and \"Churn Reason\" offer insights into customer churn dynamics within the dataset:\n",
    "\n",
    "Customer Status: This plot shows the distribution of customer statuses, such as \"Churned\", \"Stayed\", or any other categories present. It provides a clear view of the churn rate relative to the retention rate within the customer base, which is crucial for understanding overall customer satisfaction and loyalty.\n",
    "\n",
    "Churn Reason: The distribution of reasons for churn is particularly insightful, revealing the most common factors leading to customer churn. This visualization helps identify areas where improvements could potentially reduce churn rates, such as service issues, pricing concerns, or competitive offers.\n",
    "\n",
    "These insights are valuable for developing targeted strategies to improve customer satisfaction, retention, and overall service quality. By understanding the primary reasons for churn, Telco can tailor its customer service, pricing, and marketing strategies to address these concerns and enhance customer loyalty.\n",
    "\n",
    "Understanding the distribution of churn categories can help Telco focus its efforts on the most pressing issues leading to customer churn. Whether it's enhancing service quality, adjusting pricing strategies, or responding to competitive pressures, insights from this analysis are valuable for formulating targeted interventions aimed at reducing churn and improving customer loyalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship among the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with the relationship among the variables, all the five datasets are merged into one data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From domain expert knowledge, products, services, and charges are the main contributers to churn in telco. I will analyse the relatioship between churn and these variables\n",
    "\n",
    "demographics, location, services and status has variable Count which the count of the occurance of each of the CustomerID.\n",
    "These create duplicate in the merge dataframe, hence are droped before the merger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To procced the analysis i will remove some uncessary variables based on my domain expert capabilities\n",
    "the varaibles are:\n",
    "Lat Long --Location identifier, ZIP code is enough to identify the location\n",
    "Latitude --Location identifier, ZIP code is enough to identify the location\n",
    "Longitude --Location identifier, ZIP code is enough to identify the location\n",
    "Customer ID ---unique identifier of each customer. has no impact\n",
    "Customer Status -- identifier of churn status. this taken care of by Churn Label\n",
    "Churn Value --identifier of churn status. this taken care of by Churn Label\n",
    "ID - Identifier for population. has no impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics.drop(\"Count\", axis=1, inplace=True)\n",
    "location.drop(\"Count\", axis=1, inplace=True)\n",
    "services.drop(\"Count\", axis=1, inplace=True)\n",
    "status.drop(\"Count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    pd.merge(\n",
    "        pd.merge(\n",
    "            pd.merge(\n",
    "                demographics,\n",
    "                location,\n",
    "                on=\"Customer ID\",\n",
    "            ),\n",
    "            services,\n",
    "            on=\"Customer ID\",\n",
    "        ),\n",
    "        status,\n",
    "        on=\"Customer ID\",\n",
    "    ),\n",
    "    population,\n",
    "    on=\"Zip Code\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['Lat Long', 'Latitude', 'Longitude', 'Customer ID', 'Customer Status', 'Churn Value', 'ID']\n",
    "df = df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satisfaction Score and Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.violinplot(x='Churn Label', y='Satisfaction Score',\n",
    "               data=status, palette='Pastel1', inner='quartile')\n",
    "plt.title('Satisfaction Scores Density by Churn Label')\n",
    "plt.xlabel('Churn Label')\n",
    "plt.ylabel('Satisfaction Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot further elucidates the density and distribution of \"Satisfaction Scores\" by \"Churn Label\"\n",
    "There's a noticeable difference in the average satisfaction scores between customers who churn and those who do not, suggesting that lower satisfaction is associated with higher churn rates.\n",
    "The violin plot's density aspect highlights where satisfaction scores are most concentrated, offering clues to the satisfaction levels that are most common among churned versus not churned customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offers and Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to analyze\n",
    "variables = ['Offer', 'Gender', 'Under 30', 'Senior Citizen', 'Multiple Lines',\n",
    "                        'Contract', 'Unlimited Data', 'Online Backup', 'Device Protection Plan',\n",
    "                        'Premium Tech Support', 'Streaming TV']\n",
    "\n",
    "# Analysis: Count and Churn Rate by Category for each variable\n",
    "analysis_results = {}\n",
    "\n",
    "for var in variables:\n",
    "    count_by_category = df.groupby(\n",
    "        [var, 'Churn Label']).size().unstack(fill_value=0)\n",
    "\n",
    "    # Calculate churn rate by category\n",
    "    churn_rate_by_category = count_by_category['Yes'] / \\\n",
    "        (count_by_category['Yes'] + count_by_category['No'])\n",
    "\n",
    "    analysis_results[var] = {\n",
    "        'Count by Category': count_by_category,\n",
    "        'Churn Rate by Category': churn_rate_by_category\n",
    "    }\n",
    "\n",
    "\n",
    "offer_variable = 'Offer'\n",
    "analysis_results[offer_variable]['Count by Category'], analysis_results[offer_variable]['Churn Rate by Category']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "churn_rate_by_offer = analysis_results['Offer']['Churn Rate by Category']\n",
    "sns.barplot(x=churn_rate_by_offer.index, y=churn_rate_by_offer.values)\n",
    "plt.title('Churn Rate by Offer Type')\n",
    "plt.xlabel('Offer Type')\n",
    "plt.ylabel('Churn Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bar plot visualizes the churn rate by offer type, clearly illustrating how the churn rate varies significantly across different offers. Offers E and D have notably higher churn rates compared to others, indicating a strong relationship between the type of offer a customer receives and their likelihood of churning. Offers A and B are associated with the lowest churn rates, suggesting these offers might be more effective in retaining customers.\n",
    "\n",
    "This visualization provides a clear depiction of how different offers impact customer churn, offering valuable insights into which offers may need to be reevaluated or modified to reduce churn rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Churn in relation to selected variables:\n",
    "variables = ['Offer', 'Gender', 'Under 30', 'Senior Citizen', 'Multiple Lines',\n",
    "                        'Contract', 'Unlimited Data', 'Online Backup', 'Device Protection Plan',\n",
    "                        'Premium Tech Support', 'Streaming TV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_rows = (len(variables) + 1) // 2\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, 2, figsize=(12, 6*num_rows))\n",
    "\n",
    "# Flatten axs if num_rows is 1\n",
    "if num_rows == 1:\n",
    "    axs = axs.reshape(1, -1)\n",
    "\n",
    "# Plot count plots for each variable\n",
    "for i, var in enumerate(variables):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    sns.countplot(x=var, hue='Churn Label',\n",
    "                  data=df, ax=axs[row, col], palette='Set1')\n",
    "    axs[row, col].set_title(f'Churn Label across {var}')\n",
    "    axs[row, col].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The series of bar plots visualize the churn rates across different categories for each of the variables listed:\n",
    "\n",
    "Gender: The churn rate appears to be somewhat balanced between different genders, suggesting that gender alone may not be a strong predictor of churn.\n",
    "Under 30: There is a distinction in churn rates based on whether customers are under 30, indicating age might influence churn behavior.\n",
    "Senior Citizen: Senior citizen status shows a noticeable difference in churn rates, potentially indicating different needs or satisfaction levels within this group.\n",
    "Multiple Lines: Customers with and without multiple lines have varied churn rates, which could reflect on service satisfaction or usage patterns.\n",
    "Contract: There's a significant variance in churn rates based on the type of contract, with longer contracts possibly indicating lower churn rates.\n",
    "Unlimited Data: The presence of unlimited data options appears to influence churn rates, which could be a critical factor in customer retention.\n",
    "Online Backup, Device Protection Plan, Premium Tech Support, Streaming TV: Each of these services shows different churn rates among their categories, suggesting that the value or satisfaction customers derive from these services can impact their likelihood to churn.\n",
    "These visualizations provide a comprehensive overview of how different factors relate to customer churn, highlighting areas where targeted strategies could potentially improve retention. Each variable's churn rate variation suggests specific customer segments or service features that are more closely associated with higher churn rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HeatMap for numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = df.select_dtypes(include='number')\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numerical_df.corr(method=\"pearson\"))\n",
    "plt.title('Heatmap of Numerical Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_stats = df.describe().loc[['min', 'max']]\n",
    "\n",
    "print(numerical_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name, dtype in df.dtypes.items():\n",
    "    print(f\"{column_name}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check which varaiables are type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column_name, dtype in df.dtypes.items():\n",
    "    if dtype == 'object':\n",
    "        print(f\"{column_name}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zip Code is a label or identifier rather than a numerical value that you would perform mathematical operations on. Hence, comvert ZIP code to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Zip Code'] = df['Zip Code'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing value value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().any()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count = df.isnull().sum()\n",
    "missing_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_missing_value =  missing_count[missing_values > 0]\n",
    "columns_with_missing_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three variables have missing values, offer, nternet Type, Churn category, Churn Reason. \n",
    "customers with missing values for internet type and offer with be replace with value Unknown.\n",
    "\n",
    "further analysis to check if there are any customers who has churn but has null value for Churn Category or Churn reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_missing_churn_category = df[(df['Churn Label'] == 'Yes') & (df['Churn Category'].isnull())].shape[0]\n",
    "count_missing_churn_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_missing_churn_reason = df[(df['Churn Label'] == 'Yes') & (df['Churn Reason'].isnull())].shape[0]\n",
    "count_missing_churn_reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the missing values for Churn Category and churn Reason are those customer who have not churn. which is obvius.\n",
    "These missing values will be replaced with value NOT Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in column 'Internet Type' with Unknown\n",
    "df['Internet Type'] = df['Internet Type'].fillna('Unknown')\n",
    "# Replace missing values in column 'Offer' with Unknown\n",
    "df['Offer'] = df['Offer'].fillna('Unknown')\n",
    "# Replace missing values in column 'Churn Category' with NOT Churn\n",
    "df['Churn Category'] = df['Churn Category'].fillna('NOT Churn')\n",
    "\n",
    "# Replace missing values in column 'Churn Reason' with NOT Churn\n",
    "df['Churn Reason'] = df['Churn Reason'].fillna('Not Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_duplicate = df.duplicated().values.any()\n",
    "any_duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rmoving duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking if there are any column that has the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if all values in a column are the same\n",
    "def column_has_same_values(column):\n",
    "    return column.nunique() == 1\n",
    "\n",
    "\n",
    "# Check if each column has the same values\n",
    "for column_name, column in df.items():\n",
    "    if column_has_same_values(column):\n",
    "        print(f\"{column_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column Country, State, Quarter_x and Quater_y has the same values hence are dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Country\", \"State\", \"Quarter_x\", \"Quarter_y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection and Treatment:\n",
    "List of numerical columns to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Age', 'Number of Dependents',  'Number of Referrals', 'Tenure in Months', \n",
    "                      'Avg Monthly Long Distance Charges', 'Avg Monthly GB Download', 'Monthly Charge',\n",
    "                     'Total Charges',  'Total Refunds', 'Total Extra Data Charges',  \n",
    "                     'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score',\n",
    "                       'Churn Score', 'CLTV', 'Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize outliers using boxplots\n",
    "def visualize_outliers(df, columns):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, column in enumerate(columns, 1):\n",
    "        plt.subplot(len(columns), 1, i)\n",
    "        sns.boxplot(x=df[column])\n",
    "        plt.title(f'Boxplot of {column}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize outliers for numerical columns\n",
    "visualize_outliers(df, numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, 8 numeric variables have outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect and treat outliers using IQR\n",
    "def detect_and_treat_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Detect outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "\n",
    "    # Treat outliers by capping\n",
    "    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "    return df, outliers\n",
    "\n",
    "\n",
    "# Detect and treat outliers for each numerical column\n",
    "outliers_info = {}\n",
    "for column in numerical_columns:\n",
    "    df, outliers = detect_and_treat_outliers(df, column)\n",
    "    outliers_info[column] = outliers\n",
    "\n",
    "# Display information about outliers\n",
    "for column, outliers in outliers_info.items():\n",
    "    print(f'Column: {column}, Number of Outliers: {len(outliers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treatment of Outliers\n",
    "Number of dependents however has significant number of outliers. droping this values will significantly impact the number of records.\n",
    "I will use log transformation to take care of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation to take care of the outliers\n",
    "df['Number of Dependents'] = np.log1p(df['Number of Dependents'])\n",
    "df['Number of Referrals'] = np.log1p(df['Number of Referrals'])\n",
    "df['Avg Monthly GB Download'] = np.log1p(df['Avg Monthly GB Download'])\n",
    "df['Total Refunds'] = np.log1p(df['Total Refunds'])\n",
    "df['Total Extra Data Charges'] = np.log1p(df['Total Extra Data Charges'])\n",
    "df['Total Long Distance Charges'] = np.log1p(df['Total Long Distance Charges'])\n",
    "df['Total Revenue'] = np.log1p(df['Total Revenue'])\n",
    "df['Population'] = np.log1p(df['Population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical features\n",
    "To effectively handle categorical variables through encoding techniques, it's essential to understand the nature of each categorical variable in your dataset. Categorical variables can be broadly classified into two types: nominal (where there is no inherent order among the categories) and ordinal (where the categories have a natural order). The choice of encoding technique depends on the type of categorical variable\n",
    "\n",
    "Nominal Variables without a Large Number of Categories:\n",
    "\n",
    "Variables: Gender, Under 30, Senior Citizen, Married, Dependents, Referred a Friend, Phone Service, Multiple Lines, Internet Service, Internet Type, Online Security, Online Backup, Device Protection Plan, Premium Tech Support, Streaming TV, Streaming Movies, Streaming Music, Unlimited Data, Paperless Billing, Payment Method, Customer Status, Churn Label, Churn Category.\n",
    "\n",
    "\n",
    "For the high-cardinality variables ('City', 'Zip Code', 'Churn Reason'), a straightforward approach could be to use label encoding. This approach will not capture the geographical proximity but will allow us to transform these features into a model-readable format.\n",
    "\n",
    "'Churn Reason': This variable has many unique values, each providing specific reasons for churn. A label encoding can be applied here as well,\n",
    "\n",
    "To avoid creating new columns, i will use label encoding for all the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Iterate over each column\n",
    "for col in df.columns:\n",
    "    # Encode only if the column is categorical\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = label_encoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of important features that contribute to the model’s performance.\n",
    "Given the nature of this dataset, selecting important features that contribute to the model’s performance involves considering both the diversity of feature types and the potential multicollinearity among them. The following methods were used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain Knowledge: Incorporate domain knowledge to evaluate whether features logically contribute to customer churn.\n",
    "The Aim is to predict if customer will churn or not. At the point of determing if customer will churn, Churn Category\tChurn Reason will not be available. hence these two features need to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Churn Category',\t'Churn Reason'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest for Feature Importance: A Random Forest classifier was used to assess the importance of each feature in predicting the target variable (Churn Label). The feature importances were plotted, and features with importance greater than 0.01 were considered important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df.drop('Churn Label', axis=1)\n",
    "y = df['Churn Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest for feature importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=feature_importances, y=X.columns)\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Select top features based on importance\n",
    "important_features = X.columns[feature_importances > 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features based on importance\n",
    "important_features = X.columns[feature_importances > 0.01]\n",
    "important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Dimensionality Reduction using Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Standardize the features before applying PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.98)  # Retain 95% of the variance\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data into training and test sets using the PCA-transformed data\n",
    "X_train_pca, X_test_pca, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a model using the PCA-transformed data\n",
    "model_pca = LogisticRegression()\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f'Accuracy (PCA): {accuracy_pca:.2f}')\n",
    "print('\\nClassification Report (PCA):\\n',\n",
    "      classification_report(y_test, y_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fit PCA on scaled data\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Get the loadings (coefficients) of the original features in the principal components\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=[\n",
    "                        f'PC{i+1}' for i in range(pca.n_components_)], index=X.columns)\n",
    "\n",
    "# Display the loadings for the first few principal components\n",
    "print(loadings.head())\n",
    "\n",
    "# To identify important features for a specific principal component\n",
    "\n",
    "important_features_pc1 = loadings['PC1'].abs().sort_values(\n",
    "    ascending=False).head() \n",
    "print('\\nImportant features for PC1:\\n', important_features_pc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of new features that improve the model’s predictive power\n",
    "\n",
    "4 new features were created \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Interaction Features: Create new features that are the product of two or more existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Long Distance Charges'] = df['Tenure in Months'] * \\\n",
    "    df['Avg Monthly Long Distance Charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ratio Features: Create features that are the ratio of two existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Referral Rate'] = df['Number of Referrals'] / df['Tenure in Months']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Aggregated Features: creating features based on categorical featured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_charges_by_internet_type = df.groupby(\n",
    "    'Internet Type')['Avg Monthly GB Download'].mean().to_dict()\n",
    "df['Avg Charges by Internet Type'] = df['Internet Type'].map(\n",
    "    avg_charges_by_internet_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Binning: Convert continuous features into categorical features by binning them into intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age Group'] = pd.cut(df['Age'], bins=[0, 30, 60, 90], labels=[\n",
    "                           'Young', 'Middle-Aged', 'Senior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding the new Age Group feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age Group'] = label_encoder.fit_transform(df['Age Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_for_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling and normalization of numerical features\n",
    "Age, Tenure in Months, Monthly Charge, Total Charges, Churn Score, CLTV, Population:\n",
    "\n",
    "These variables display a wide range of values and could benefit from Standardization (Z-score scaling), as it centers the data around the mean with a unit standard deviation, making it suitable for algorithms that assume data is centered around 0.\n",
    "Number of Dependents, Number of Referrals, Avg Monthly Long Distance Charges, Avg Monthly GB Download, Total Refunds, Total Extra Data Charges, Total Long Distance Charges, Total Revenue, Satisfaction Score, Churn Value:\n",
    "\n",
    "Many of these variables exhibit skewed distributions or have a significant proportion of zero values. For variables with a non-normal distribution, Normalization (Min-Max Scaling) could be more appropriate to rescale the data within a specific range (0 to 1), especially if the model benefits from bounded values.\n",
    "For \"Total Refunds\" and \"Total Extra Data Charges\", which are constants (zeros in this case), scaling or normalization is not applicable as these features do not vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe before scaling: to be used later\n",
    "df_nonscaled = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_standardize = ['Age', 'Tenure in Months', 'Monthly Charge',\n",
    "                          'Total Charges', 'Churn Score', 'CLTV', 'Population']\n",
    "columns_to_normalize = ['Number of Referrals', 'Avg Monthly Long Distance Charges', 'Avg Monthly GB Download',\n",
    "                        'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score']\n",
    "\n",
    "# Initialize scalers\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_min_max = MinMaxScaler()\n",
    "\n",
    "\n",
    "# Apply standardization\n",
    "df[columns_to_standardize] = scaler_standard.fit_transform(\n",
    "    df[columns_to_standardize])\n",
    "\n",
    "# Apply normalization\n",
    "df[columns_to_normalize] = scaler_min_max.fit_transform(\n",
    "    df[columns_to_normalize])\n",
    "\n",
    "# Display summary statistics of the transformed variables to verify changes\n",
    "df[columns_to_standardize + columns_to_normalize].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of an appropriate supervised learning algorithm that suits the problem.\n",
    "Selection of an Appropriate Supervised Learning Algorithm\n",
    "For churn prediction, which is a binary classification problem (churn or not churn), some commonly used supervised learning algorithms are:\n",
    "\n",
    "Logistic Regression\n",
    "Decision Trees\n",
    "Random Forest\n",
    "Gradient Boosting Machines (e.g., XGBoost, LightGBM)\n",
    "Support Vector Machines (SVM)\n",
    "Neural Networks\n",
    "The choice of algorithm depends on the size and nature of your dataset, the interpretability of the model, and the computational resources available. \n",
    "\n",
    "The choosen Algorithm is Random Forest. \n",
    "Random Forest is an ensemble method that can handle both numerical and categorical data well. It is robust to outliers and can capture complex interactions between features. \n",
    "It can handle a mix of feature types well. Additionally, it often perform well out-of-the-box with default parameters, which can be a good starting point before tuning for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development and training of the model using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop rows with NaN values and separate the features and target variable\n",
    "df_clean = df.dropna()\n",
    "X = df_clean.drop(columns=['Churn Label'])\n",
    "y = df_clean['Churn Label']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning of hyperparameters to optimize the model’s performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           n_jobs=-1,  # Use all available cores\n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier with the specified parameters\n",
    "rf_model_tuned = RandomForestClassifier(n_estimators=100,\n",
    "                                  max_depth=10,\n",
    "                                  min_samples_split=5,\n",
    "                                  min_samples_leaf=2,\n",
    "                                  random_state=42)\n",
    "rf_model_tuned.fit(X_train, y_train)\n",
    "y_pred_tuned = rf_model_tuned.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "classification_rep_tuned = classification_report(y_test, y_pred_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_rep_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using only Suggested iportant features only amd measuring the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = ['Age', 'Dependents', 'Zip Code', 'Number of Referrals',\n",
    " 'Tenure in Months', 'Internet Type', 'Avg Monthly GB Download',\n",
    " 'Contract', 'Monthly Charge', 'Total Charges',\n",
    " 'Total Long Distance Charges', 'Total Revenue', 'Satisfaction Score',\n",
    " 'Churn Score', 'CLTV']\n",
    "\n",
    "target_feature = ['Churn Label']\n",
    "X = df[important_features]\n",
    "y = df[target_feature]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_model_important_feactures = RandomForestClassifier(random_state=42)\n",
    "rf_model_important_feactures.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_important_features = rf_model_important_feactures.predict(X_test)\n",
    "\n",
    "accuracy_important_feactures = accuracy_score(y_test, y_pred_important_features)\n",
    "classification_rep_important_feactures = classification_report(y_test, y_pred_important_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_important_feactures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_rep_important_feactures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance before turning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_before_tune = accuracy_score(y_test, y_pred)\n",
    "precision_before_tuned = precision_score(y_test, y_pred)\n",
    "recall_before_tuned = recall_score(y_test, y_pred)\n",
    "f1_score_before_tuned = f1_score(y_test, y_pred)\n",
    "print(accuracy_before_tune, precision_before_tuned,\n",
    "      recall_before_tuned, f1_score_before_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance after tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "f1_score_tuned = f1_score(y_test, y_pred_tuned)\n",
    "(accuracy_tuned, precision_tuned, recall_tuned, f1_score_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "\n",
    "(cv_mean, cv_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that the model performs consistently well across different folds, with a high average accuracy and low variability. This suggests that the model is robust and generalizes well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_tuned)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
